{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo1u4MhtoRPjnhkQBcen3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rasiq-gulzar/Encryptix/blob/main/titanic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd              # For data manipulation and analysis\n",
        "import numpy as np               # For numerical operations\n",
        "import seaborn as sns            # For statistical data visualization\n",
        "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
        "from sklearn.model_selection import train_test_split  # To split data into training and testing sets\n",
        "from sklearn.preprocessing import LabelEncoder         # To encode categorical variables into numbers\n",
        "from sklearn.impute import SimpleImputer               # To handle missing values in the dataset\n",
        "from sklearn.linear_model import LogisticRegression    # The classification algorithm we'll use\n",
        "from sklearn.metrics import accuracy_score, classification_report  # For evaluating model performance\n",
        "\n",
        "df=pd.read_csv('/content/Titanic-Dataset (1).csv')\n",
        "# Select only the important features from the Titanic dataset\n",
        "# Removing irrelevant columns like Name, Ticket number, Cabin, etc. that won't contribute much to prediction\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "\n",
        "# Handle missing values in the Age column by replacing them with the mean age\n",
        "# This is necessary because machine learning models can't work with missing (NaN) values\n",
        "imputer = SimpleImputer(strategy=\"mean\")  # Create an imputer that replaces missing values with the mean\n",
        "df['Age'] = imputer.fit_transform(df[['Age']])  # Apply the imputer to the Age column\n",
        "\n",
        "# Convert categorical 'Sex' variable to numerical values (0 and 1)\n",
        "# Machine learning models require numerical input, so text values like 'male' and 'female' must be encoded\n",
        "encoder = LabelEncoder()  # Create a label encoder object\n",
        "df['Sex'] = encoder.fit_transform(df['Sex'])  # Transform 'male' and 'female' to 1 and 0 respectively\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop(\"Survived\", axis=1)  # Features: everything except the Survived column\n",
        "y = df[\"Survived\"]               # Target: the Survived column (what we want to predict)\n",
        "\n",
        "# Split the data into training set (80%) and testing set (20%)\n",
        "# This allows us to train the model and then test it on unseen data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# random_state=0 ensures reproducible results (same split every time the code runs)\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "# Logistic regression is well-suited for binary classification problems like survival prediction\n",
        "model = LogisticRegression()  # Initialize the logistic regression model\n",
        "model.fit(X_train, y_train)   # Train the model using the training data\n",
        "\n",
        "# Use the trained model to predict survival for the test set\n",
        "y_pred = model.predict(X_test)  # Make predictions on the test data\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)  # Calculate the percentage of correct predictions\n",
        "print(f\"Accuracy: {accuracy:.2f}\")          # Print the accuracy with 2 decimal places\n",
        "\n",
        "# Print a detailed classification report\n",
        "# This shows precision, recall, f1-score and support for each class (survived or not)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Create example passenger data to demonstrate how to use the model for new predictions\n",
        "sample_data = pd.DataFrame({\n",
        "    'Pclass': [3, 1, 3, 1, 2],    # Ticket class (1=1st class, 2=2nd class, 3=3rd class)\n",
        "    'Sex': [1, 0, 0, 1, 0],       # Gender encoded (Male=1, Female=0)\n",
        "    'Age': [22, 38, 26, 35, 28],  # Age of passengers in years\n",
        "    'SibSp': [1, 1, 0, 1, 0],     # Number of siblings/spouses aboard\n",
        "    'Parch': [0, 0, 0, 1, 0],     # Number of parents/children aboard\n",
        "    'Fare': [7.25, 71.28, 8.05, 53.1, 13]  # Ticket fare in pounds\n",
        "})\n",
        "\n",
        "# Predict survival for the sample passengers\n",
        "sample_predictions = model.predict(sample_data)\n",
        "print(\"Predictions for sample input (1=Survived, 0=Not Survived):\", sample_predictions)\n",
        "# This shows survival predictions for each passenger in the sample data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZvUM1Tm1CvL",
        "outputId": "6473ff3d-57d9-41df-d60a-a99722e4aaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.84       110\n",
            "           1       0.75      0.71      0.73        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.79      0.78      0.79       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n",
            "Predictions for sample input (1=Survived, 0=Not Survived): [0 1 1 0 1]\n"
          ]
        }
      ]
    }
  ]
}